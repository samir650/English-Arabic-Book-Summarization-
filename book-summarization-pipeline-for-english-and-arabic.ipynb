{"cells":[{"cell_type":"markdown","metadata":{"id":"QZMIzjWGCmyw"},"source":["# **Introduction**\n","This notebook provides an end-to-end pipeline for summarizing both English and Arabic books. It involves extracting text from a PDF, dividing the text into semantically coherent chunks, summarizing each chunk, and finally generating a PDF output of the summary. The pipeline automatically detects the language of the book and applies the appropriate summarization model. The summarization models used are optimized to run on GPUs, ensuring efficiency for large texts.\n","\n","The steps for the pipeline include:\n","\n","1. **Text Extraction**: Extract the raw text from the PDF file.\n","2. **Language Detection**: Detect whether the text is in English or Arabic.\n","3. **Semantic Chunking**: Break the text into semantically meaningful chunks based on sentence embeddings or natural chunking (depending on the language).\n","4. **Text Summarization**: Summarize each chunk using the appropriate model (BART for English, mT5 for Arabic).\n","5. **PDF Generation**: Create a PDF file containing the summarized text.\n"]},{"cell_type":"markdown","metadata":{"id":"2GNSlUblC8gR"},"source":["# **Pipeline Steps**\n"]},{"cell_type":"markdown","metadata":{"id":"kSZ1DELyDDkO"},"source":["## Step 1: Install the Required Libraries\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T20:56:52.405418Z","iopub.status.busy":"2024-09-19T20:56:52.405101Z","iopub.status.idle":"2024-09-19T20:58:46.461419Z","shell.execute_reply":"2024-09-19T20:58:46.460179Z","shell.execute_reply.started":"2024-09-19T20:56:52.405386Z"},"id":"AtasHXj1C5I1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting PyMuPDF\n","  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n","Collecting arabic_reshaper\n","  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (0.6.0)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n","Collecting reportlab\n","  Downloading reportlab-4.2.2-py3-none-any.whl.metadata (1.4 kB)\n","Collecting fpdf2\n","  Downloading fpdf2-2.7.9-py2.py3-none-any.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyMuPDFb==1.24.10 (from PyMuPDF)\n","  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n","Collecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (9.5.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n","Collecting chardet (from reportlab)\n","  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from fpdf2) (0.7.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n","Downloading reportlab-4.2.2-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fpdf2-2.7.9-py2.py3-none-any.whl (206 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.4/206.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: arabic_reshaper, pypdfium2, PyMuPDFb, fpdf2, chardet, reportlab, PyMuPDF, pdfminer.six, pdfplumber\n","Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10 arabic_reshaper-3.0.0 chardet-5.2.0 fpdf2-2.7.9 pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0 reportlab-4.2.2\n","Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.5)\n","Collecting camel-tools\n","  Downloading camel_tools-1.5.5-py3-none-any.whl.metadata (10 kB)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n","Collecting fpdf\n","  Downloading fpdf-1.7.2.tar.gz (39 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting stanza\n","  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.12.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.8.2)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (70.0.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\n","Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from camel-tools) (1.0.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from camel-tools) (1.16.0)\n","Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from camel-tools) (0.6.2)\n","Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from camel-tools) (4.2.4)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from camel-tools) (1.14.0)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from camel-tools) (2.2.2)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from camel-tools) (1.2.2)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from camel-tools) (0.3.8)\n","Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.10/site-packages (from camel-tools) (2.4.0)\n","Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n","  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting editdistance (from camel-tools)\n","  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n","Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from camel-tools) (2.12.1)\n","Collecting pyrsistent (from camel-tools)\n","  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from camel-tools) (0.9.0)\n","Collecting muddler (from camel-tools)\n","  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n","Collecting camel-kenlm>=2024.5.6 (from camel-tools)\n","  Downloading camel-kenlm-2024.5.6.zip (556 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: protobuf>=3.15.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (3.20.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from stanza) (3.3)\n","Requirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0->camel-tools) (1.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.19.1)\n","Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->camel-tools) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->camel-tools) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->camel-tools) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->camel-tools) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->camel-tools) (3.5.0)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0->camel-tools) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Downloading camel_tools-1.5.5-py3-none-any.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.5/124.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading muddler-0.1.3-py3-none-any.whl (16 kB)\n","Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fpdf, langdetect, camel-kenlm\n","  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40702 sha256=796eb4d598d4f2aeeb35aabd5454fd84ea128f4469ad18f10489825765a1084c\n","  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n","  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=a748b1b35273f03c0de3a7fa4a91cd8b266877bfd620589f97bdfb29c4f639f2\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for camel-kenlm: filename=camel_kenlm-2024.5.6-cp310-cp310-linux_x86_64.whl size=587536 sha256=6c2680d269888a8b032bb0c6c31631b695b74c20caf216d92ef72de49202af85\n","  Stored in directory: /root/.cache/pip/wheels/2b/93/ff/ac84dae74c91ffe3e1c344a71f991946eacc79eada61cb703f\n","Successfully built fpdf langdetect camel-kenlm\n","Installing collected packages: fpdf, camel-kenlm, pyrsistent, PyPDF2, muddler, langdetect, editdistance, stanza, transformers, sentence-transformers, camel-tools\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.0\n","    Uninstalling transformers-4.44.0:\n","      Successfully uninstalled transformers-4.44.0\n","Successfully installed PyPDF2-3.0.1 camel-kenlm-2024.5.6 camel-tools-1.5.5 editdistance-0.8.1 fpdf-1.7.2 langdetect-1.0.9 muddler-0.1.3 pyrsistent-0.20.0 sentence-transformers-3.1.1 stanza-1.9.2 transformers-4.43.4\n"]}],"source":["!pip install PyMuPDF pdfplumber transformers arabic_reshaper python-bidi matplotlib reportlab fpdf2\n","!pip install spacy camel-tools sentence-transformers fpdf PyPDF2 stanza langdetect\n"]},{"cell_type":"markdown","metadata":{"id":"D3hWFd0YDGzU"},"source":["## Step 2: Import Required Libraries\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T20:58:46.463780Z","iopub.status.busy":"2024-09-19T20:58:46.463431Z","iopub.status.idle":"2024-09-19T20:59:07.927306Z","shell.execute_reply":"2024-09-19T20:59:07.926463Z","shell.execute_reply.started":"2024-09-19T20:58:46.463743Z"},"id":"1iSpPrZODIs9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]}],"source":["from sentence_transformers import SentenceTransformer, util\n","from transformers import pipeline\n","import re\n","from fpdf import FPDF\n","import shutil\n","import pdfplumber\n","import arabic_reshaper\n","from bidi.algorithm import get_display\n","import stanza\n","from langdetect import detect\n"]},{"cell_type":"markdown","metadata":{"id":"k_B6KNKbDKh9"},"source":["## Step 3: Download the Arabic Language Model for Stanza\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T20:59:07.929157Z","iopub.status.busy":"2024-09-19T20:59:07.928451Z","iopub.status.idle":"2024-09-19T20:59:14.487495Z","shell.execute_reply":"2024-09-19T20:59:14.486645Z","shell.execute_reply.started":"2024-09-19T20:59:07.929122Z"},"id":"-jYp3RW3DOU7","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f649b6ed98c14eceb9f3957897046513","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adeb320e3c7b4311bdeb8a3c7d7eb0eb","version_major":2,"version_minor":0},"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-ar/resolve/v1.9.0/models/default.zip:   0%|          | 0…"]},"metadata":{},"output_type":"display_data"}],"source":["stanza.download('ar')\n"]},{"cell_type":"markdown","metadata":{"id":"oRaC1ay-DPlB"},"source":["## Step 4: Define Helper Functions for Text Extraction and Cleaning\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:07:22.298189Z","iopub.status.busy":"2024-09-19T22:07:22.297747Z","iopub.status.idle":"2024-09-19T22:07:22.305998Z","shell.execute_reply":"2024-09-19T22:07:22.304865Z","shell.execute_reply.started":"2024-09-19T22:07:22.298154Z"},"id":"fSIbF8KIDMz1","trusted":true},"outputs":[],"source":["# Extract text from the PDF file using pdfplumber\n","def extract_text_from_pdf(pdf_path):\n","    with pdfplumber.open(pdf_path) as pdf:\n","        text = ''.join(page.extract_text() for page in pdf.pages)\n","    return text\n","\n","# Function: Arabic Text Reshaping and Bidi Fix\n","def fix_arabic_text(text):\n","    reshaped_text = arabic_reshaper.reshape(text)\n","    return get_display(reshaped_text)\n","\n","\n","# Clean the text by removing URLs, numbers, and extra spaces\n","def clean_text(text):\n","    text = re.sub(r'http\\S+', '', text)\n","    text = re.sub(r'\\b\\d+\\b', '', text)\n","    text = re.sub(r'\\b[A-Za-z]\\b', '', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n"]},{"cell_type":"markdown","metadata":{"id":"iMaKCe0yDUJy"},"source":["## Step 5: Set Up the Sentence-BERT Model and Summarizer Models\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:07:30.661255Z","iopub.status.busy":"2024-09-19T22:07:30.660855Z","iopub.status.idle":"2024-09-19T22:07:42.220080Z","shell.execute_reply":"2024-09-19T22:07:42.218295Z","shell.execute_reply.started":"2024-09-19T22:07:30.661217Z"},"id":"cpTabKPbDR7O","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"064fcd7bd88b43939c2053eaa066c88a","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"]},"metadata":{},"output_type":"display_data"}],"source":["# Load pre-trained Sentence-BERT model for semantic embeddings (ensure GPU usage)\n","model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n","summarizer_en = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n","summarizer_ar = pipeline('summarization', model='csebuetnlp/mT5_multilingual_XLSum', device=0)\n","nlp_ar = stanza.Pipeline('ar', processors='tokenize')\n"]},{"cell_type":"markdown","metadata":{"id":"FTqKq2B1DWn3"},"source":["## Step 6: Define the Function for Semantic Chunking in English\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:07:42.222428Z","iopub.status.busy":"2024-09-19T22:07:42.222068Z","iopub.status.idle":"2024-09-19T22:07:42.232609Z","shell.execute_reply":"2024-09-19T22:07:42.231637Z","shell.execute_reply.started":"2024-09-19T22:07:42.222384Z"},"id":"TiAfmvCQDY23","trusted":true},"outputs":[],"source":["def divide_by_semantics_with_length(text, threshold=0.6, max_words=800, min_words=400):\n","    sentences = text.split('. ')\n","    embeddings = model.encode(sentences, convert_to_tensor=True)\n","    chunks = []\n","    current_chunk = sentences[0]\n","\n","    for i in range(1, len(sentences)):\n","        similarity = util.pytorch_cos_sim(embeddings[i], embeddings[i - 1])\n","        current_word_count = len(current_chunk.split())\n","\n","        if similarity < threshold or current_word_count + len(sentences[i].split()) > max_words:\n","            if current_word_count >= min_words:\n","                chunks.append(current_chunk.strip())\n","                current_chunk = sentences[i]\n","            else:\n","                current_chunk += '. ' + sentences[i]\n","        else:\n","            current_chunk += '. ' + sentences[i]\n","\n","    if len(current_chunk.split()) >= min_words:\n","        chunks.append(current_chunk.strip())\n","\n","    return chunks\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7: Define the Function for Semantic Chunking in Arabic"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:07:42.234444Z","iopub.status.busy":"2024-09-19T22:07:42.234084Z","iopub.status.idle":"2024-09-19T22:07:42.248757Z","shell.execute_reply":"2024-09-19T22:07:42.247870Z","shell.execute_reply.started":"2024-09-19T22:07:42.234402Z"},"trusted":true},"outputs":[],"source":["# Function: Semantic Chunking (Arabic)\n","def chunk_arabic_text(text, min_words=300, max_words=500):\n","    \"\"\"Break the Arabic text into semantically meaningful chunks.\"\"\"\n","    doc = nlp_ar(text)\n","    chunks = []\n","    current_chunk = []\n","    current_chunk_word_count = 0\n","\n","    for sentence in doc.sentences:\n","        sentence_text = sentence.text\n","        sentence_word_count = len(sentence_text.split())\n","\n","        # If the sentence is too long, split it into smaller sentences\n","        if sentence_word_count > max_words:\n","            split_sentences = split_long_sentence(sentence_text, max_words)\n","        else:\n","            split_sentences = [sentence_text]\n","\n","        # Add the split sentences to the current chunk\n","        for split_sentence in split_sentences:\n","            split_sentence_word_count = len(split_sentence.split())\n","            if current_chunk_word_count + split_sentence_word_count > max_words and current_chunk_word_count >= min_words:\n","                chunks.append(' '.join(current_chunk))\n","                current_chunk = []\n","                current_chunk_word_count = 0\n","\n","            current_chunk.append(split_sentence)\n","            current_chunk_word_count += split_sentence_word_count\n","\n","    # Add the last chunk if it meets the minimum word requirement\n","    if current_chunk_word_count >= min_words:\n","        chunks.append(' '.join(current_chunk))\n","\n","    return chunks\n","\n","# Helper function to split long Arabic sentences\n","def split_long_sentence(sentence_text, max_words):\n","    words = sentence_text.split()\n","    return [' '.join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n"]},{"cell_type":"markdown","metadata":{"id":"w1Nx4LcXDaeu"},"source":["## Step 8: Define the Summarization and PDF Generation Functions\n"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:22:36.775058Z","iopub.status.busy":"2024-09-19T22:22:36.774583Z","iopub.status.idle":"2024-09-19T22:22:36.792413Z","shell.execute_reply":"2024-09-19T22:22:36.791603Z","shell.execute_reply.started":"2024-09-19T22:22:36.775017Z"},"id":"6Cw0ujwKDcau","trusted":true},"outputs":[],"source":["# Summarize text chunks\n","def summarize_chunks(chunks, summarizer, min_chunk_length=50, max_summary_length=300, min_summary_length=80):\n","    summaries = []\n","    for chunk in chunks:\n","        if len(chunk.split()) > min_chunk_length:\n","            try:\n","                summary = summarizer(chunk, max_length=max_summary_length, min_length=min_summary_length, do_sample=False)[0]['summary_text']\n","                summaries.append(summary)\n","            except Exception as e:\n","                print(f\"Error summarizing chunk: {e}\")\n","                summaries.append(chunk)\n","        else:\n","            summaries.append(chunk)\n","    return summaries\n","\n","# Generate PDF with the summarized text\n","\n","reshaped_text = arabic_reshaper.reshape(\"ملخص الكتاب\")\n","_text = get_display(reshaped_text)\n","\n","\n","class PDF(FPDF):\n","    def header(self):\n","        if self.page_no() == 1:\n","            self.set_font('DejaVu', 'B', 12)\n","            title = _text if self.language == 'ar' else 'Book Summary'\n","            self.cell(0, 10, title, ln=True, align='C')\n","            self.ln(10)\n","\n","    def chapter_body(self, body):\n","        self.set_font('DejaVu', '', 12)\n","        self.multi_cell(0, 10, body, align='R' if self.language == 'ar' else 'L')\n","        self.ln()\n","\n","    def add_text(self, text):\n","        self.add_page()\n","        self.chapter_body(text)\n","\n","# Helper function to generate the PDF\n","def generate_pdf(summary_text, pdf_output_path, language='en'):\n","    pdf = PDF()\n","    pdf.language = language\n","    pdf.add_font('DejaVu', '', '/path/to/DejaVuSans.ttf', uni=True)\n","    pdf.add_font('DejaVu', 'B', '/path/to/DejaVuSans-Bold.ttf', uni=True)\n","    pdf.set_font('DejaVu', '', 12)\n","\n","    pdf.add_text(summary_text)\n","    pdf.output(pdf_output_path)\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"x97O3lS5DeC1"},"source":["## Step 9: Define the Summarization Pipelines for English and Arabic\n"]},{"cell_type":"markdown","metadata":{"id":"ogrjlPwIDsN2"},"source":["### **English Summarization Pipeline**\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:22:38.739171Z","iopub.status.busy":"2024-09-19T22:22:38.738153Z","iopub.status.idle":"2024-09-19T22:22:38.744965Z","shell.execute_reply":"2024-09-19T22:22:38.744044Z","shell.execute_reply.started":"2024-09-19T22:22:38.739130Z"},"id":"mPF8vTk7Dg5s","trusted":true},"outputs":[],"source":["def summarize_english(book_text, pdf_output_path=\"english_summary.pdf\"):\n","    # Step 1: Divide text into semantic chunks\n","    semantic_chunks = divide_by_semantics_with_length(book_text)\n","\n","    # Step 2: Clean the chunks\n","    cleaned_chunks = [clean_text(chunk) for chunk in semantic_chunks]\n","\n","    # Step 3: Summarize the chunks\n","    summarized_chunks = summarize_chunks(cleaned_chunks, summarizer_en)\n","\n","    # Step 4: Generate PDF\n","    final_summary = '\\n\\n'.join(summarized_chunks)\n","    generate_pdf(final_summary, pdf_output_path, language='en')\n","\n","    print(f\"Summarization completed!, saved to {pdf_output_path}\")\n","    \n","    return final_summary\n"]},{"cell_type":"markdown","metadata":{"id":"DdxN7zpXDxc1"},"source":["### **Arabic Summarization Pipeline**\n"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:22:40.399727Z","iopub.status.busy":"2024-09-19T22:22:40.399058Z","iopub.status.idle":"2024-09-19T22:22:40.406377Z","shell.execute_reply":"2024-09-19T22:22:40.405382Z","shell.execute_reply.started":"2024-09-19T22:22:40.399688Z"},"id":"2fj6zaskD0qN","trusted":true},"outputs":[],"source":["def summarize_arabic(pdf_path, pdf_output_path=\"arabic_summary.pdf\"):\n","    # Step 1: Extract text from PDF and fix Arabic text direction\n","    text = extract_text_from_pdf(pdf_path)\n","    fixed_text = fix_arabic_text(text)  # Fixing the text direction\n","    \n","    # Step 2: Chunk the text semantically\n","    chunks = chunk_arabic_text(fixed_text)  # Now the chunking function is defined\n","    \n","    # Step 3: Summarize the chunks\n","    summarized_chunks = summarize_chunks(chunks, summarizer_ar)\n","    \n","    # Step 4: Clean and generate the final summary\n","    cleaned_summaries = [clean_text(chunk) for chunk in summarized_chunks]\n","    final_summary = '\\n\\n'.join(cleaned_summaries)\n","    \n","    # Step 5: Generate PDF\n","    final_summary_arabic = fix_arabic_text(final_summary)\n","    generate_pdf(final_summary_arabic, pdf_output_path, language='ar')\n","\n","    # Notify the user that the PDF has been created\n","    print(f\"Summarization completed!, saved to {pdf_output_path}\")\n","\n","    return final_summary\n"]},{"cell_type":"markdown","metadata":{"id":"q9lbQzlLD3_m"},"source":["## Step 10: Language Detection and Pipeline Execution\n"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:22:42.420325Z","iopub.status.busy":"2024-09-19T22:22:42.419936Z","iopub.status.idle":"2024-09-19T22:22:42.426163Z","shell.execute_reply":"2024-09-19T22:22:42.425190Z","shell.execute_reply.started":"2024-09-19T22:22:42.420290Z"},"id":"k4iu35ZQD3ij","trusted":true},"outputs":[],"source":["def detect_language_and_summarize(pdf_path, pdf_output_path_ar=\"arabic_summary.pdf\", pdf_output_path_en=\"english_summary.pdf\"):\n","    text = extract_text_from_pdf(pdf_path)\n","    language = detect(text)\n","\n","    if language == 'ar':\n","        print(\"Detected Arabic. Running Arabic summarization pipeline...\")\n","        return summarize_arabic(pdf_path, pdf_output_path=pdf_output_path_ar)\n","    else:\n","        print(\"Detected English. Running English summarization pipeline...\")\n","        return summarize_english(text, pdf_output_path=pdf_output_path_en)\n"]},{"cell_type":"markdown","metadata":{"id":"6OIweBAqD8QW"},"source":["## Step 11: Run the Pipeline on Your PDF\n"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T22:18:55.369681Z","iopub.status.busy":"2024-09-19T22:18:55.368776Z","iopub.status.idle":"2024-09-19T22:21:24.174656Z","shell.execute_reply":"2024-09-19T22:21:24.173624Z","shell.execute_reply.started":"2024-09-19T22:18:55.369639Z"},"id":"rKaAuRzFD-Yn","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected Arabic. Running Arabic summarization pipeline...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -64475\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65115\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65118\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65122\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65123\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65125\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65126\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n","/opt/conda/lib/python3.10/site-packages/fpdf/ttfonts.py:670: UserWarning: cmap value too big/small: -65127\n","  warnings.warn(\"cmap value too big/small: %s\" % cm)\n"]},{"name":"stdout","output_type":"stream","text":["Summarization completed!, saved to arabic_summary.pdf\n"]}],"source":["pdf_path = \"/path/to/your/book.pdf\"  # Update this to the correct PDF path\n","final_summary = detect_language_and_summarize(pdf_path)\n"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5678094,"sourceId":9364089,"sourceType":"datasetVersion"},{"datasetId":5729464,"sourceId":9430705,"sourceType":"datasetVersion"},{"datasetId":5711929,"sourceId":9407446,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
